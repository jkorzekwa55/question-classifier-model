{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f503e23",
   "metadata": {},
   "source": [
    "## Question Classification with Classical Machine Learning Models\n",
    "\n",
    "This notebook implements several **classical machine learning algorithms** for the task of **question classification** â€“ deciding whether a question **requires additional context** or can be understood independently.\n",
    "\n",
    "### ðŸ“‚ Models Implemented\n",
    "- Naive Bayes (`MultinomialNB`)  \n",
    "- Logistic Regression (`LogisticRegression`)  \n",
    "- Linear Support Vector Classifier (`LinearSVC`)  \n",
    "- Stochastic Gradient Descent Classifier (`SGDClassifier`)  \n",
    "\n",
    "### ðŸ“Š Dataset\n",
    "- **`labeled_data.csv`** â€“ custom labeled dataset with two classes:  \n",
    "  - **Needs context**  \n",
    "  - **Does not need context**\n",
    "\n",
    "### ðŸŽ¯ Goal\n",
    "- Train and evaluate baseline models for comparison with the transformer-based approach (HerBERT).  \n",
    "- Provide insights into the performance trade-offs between traditional ML models and modern transformer models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de552fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf17716",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5043750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\", encoding=\"utf-8\", sep=\";\", names=[\"text\", \"label\"])\n",
    "label_mapping = {\"bez kontekstu\": 0, \"kontekst\": 1}\n",
    "\n",
    "df[\"label\"] = df[\"label\"].map(label_mapping).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ec9886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "bez kontekstu       0.71      1.00      0.83       134\n",
      "     kontekst       1.00      0.18      0.31        66\n",
      "\n",
      "     accuracy                           0.73       200\n",
      "    macro avg       0.86      0.59      0.57       200\n",
      " weighted avg       0.81      0.73      0.66       200\n",
      "\n",
      "=== Logistic Regression ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "bez kontekstu       0.71      0.99      0.82       134\n",
      "     kontekst       0.86      0.18      0.30        66\n",
      "\n",
      "     accuracy                           0.72       200\n",
      "    macro avg       0.78      0.58      0.56       200\n",
      " weighted avg       0.76      0.72      0.65       200\n",
      "\n",
      "=== LinearSVC ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "bez kontekstu       0.74      0.85      0.79       134\n",
      "     kontekst       0.56      0.38      0.45        66\n",
      "\n",
      "     accuracy                           0.69       200\n",
      "    macro avg       0.65      0.61      0.62       200\n",
      " weighted avg       0.68      0.69      0.68       200\n",
      "\n",
      "=== SGDClassifier ===\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "bez kontekstu       0.76      0.87      0.81       134\n",
      "     kontekst       0.63      0.44      0.52        66\n",
      "\n",
      "     accuracy                           0.73       200\n",
      "    macro avg       0.70      0.66      0.67       200\n",
      " weighted avg       0.72      0.73      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"LinearSVC\": LinearSVC(),\n",
    "    \"SGDClassifier\": SGDClassifier(),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(classification_report(y_test, y_pred, target_names=list(label_mapping.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de05c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final results: {'Naive Bayes': 0.73, 'Logistic Regression': 0.72, 'LinearSVC': 0.695, 'SGDClassifier': 0.73}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
