# ❓ Question Classification: Context Needed or Not

This project explores the task of **question classification**: determining whether a given question **requires additional context** or can be understood independently.

## 📊 Dataset
The dataset is a custom-labeled file:  
- **`labeled_data.csv`** – contains manually classified polish questions with two categories:  
  - **Needs context**  
  - **Does not need context**

## 🧠 Models
### Main Model (Transformers)
- **[allegro/herbert-base-cased](https://huggingface.co/allegro/herbert-base-cased)** – a Polish BERT-based language model fine-tuned for this binary classification task.  
- Trained weights are stored in: `./model_classification/`.

### Classical ML Models
For comparison, several baseline classifiers were trained in a separate notebook (`classify_question_other_model.ipynb`):
- Naive Bayes (`MultinomialNB`)
- Logistic Regression (`LogisticRegression`)
- Linear Support Vector Classifier (`LinearSVC`)
- Stochastic Gradient Descent Classifier (`SGDClassifier`)

## 🛠️ Project Structure
question-classification/
│── labeled_data.csv # Custom labeled dataset
│── classify_question_herbert.ipynb # Notebook using HerBERT transformer model
│── classify_question_other_model.ipynb # Classical ML models
│── model_classification/ # Saved fine-tuned HerBERT model weights
│── question_labeler.py # 
│── README.md # Project documentation

## 🎯 Goals
- Build a robust classifier to detect whether a question needs context.  
- Compare the performance of transformer-based (HerBERT) vs. traditional ML models.  
- Provide insights into which approach generalizes better for this task.