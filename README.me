# â“ Question Classification: Context Needed or Not

This project explores the task of **question classification**: determining whether a given question **requires additional context** or can be understood independently.

## ğŸ“Š Dataset
The dataset is a custom-labeled file:  
- **`labeled_data.csv`** â€“ contains manually classified polish questions with two categories:  
  - **Needs context**  
  - **Does not need context**

## ğŸ§  Models
### Main Model (Transformers)
- **[allegro/herbert-base-cased](https://huggingface.co/allegro/herbert-base-cased)** â€“ a Polish BERT-based language model fine-tuned for this binary classification task.  
- Trained weights are stored in: `./model_classification/`.

### Classical ML Models
For comparison, several baseline classifiers were trained in a separate notebook (`classify_question_other_model.ipynb`):
- Naive Bayes (`MultinomialNB`)
- Logistic Regression (`LogisticRegression`)
- Linear Support Vector Classifier (`LinearSVC`)
- Stochastic Gradient Descent Classifier (`SGDClassifier`)

## ğŸ› ï¸ Project Structure
question-classification/
â”‚â”€â”€ labeled_data.csv # Custom labeled dataset
â”‚â”€â”€ classify_question_herbert.ipynb # Notebook using HerBERT transformer model
â”‚â”€â”€ classify_question_other_model.ipynb # Classical ML models
â”‚â”€â”€ model_classification/ # Saved fine-tuned HerBERT model weights
â”‚â”€â”€ question_labeler.py # 
â”‚â”€â”€ README.md # Project documentation

## ğŸ¯ Goals
- Build a robust classifier to detect whether a question needs context.  
- Compare the performance of transformer-based (HerBERT) vs. traditional ML models.  
- Provide insights into which approach generalizes better for this task.